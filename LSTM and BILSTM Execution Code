import re
import string

df = pd.read_csv('spam_ham_dataset1.csv')
df.head()

df["text"] = df.text
df["spam"] = df.label

emails_train, emails_test, target_train, target_test = train_test_split(df.text,df.spam,test_size = 0.2) 

def remove_number(word):
    res = re.sub(r'\d+', '', word)
    return res we
def remove_whitespace(word):
    res = word.strip()
    return res
def replace_newline(word):
    return word.replace('\n','')
def remove_punctuation(word):
    res = word.translate(str.maketrans(dict.fromkeys(string.punctuation)))
    return res
def to_lower(word):
    res = word.lower()
    return res
def remove_special_characters(word):
    res = word.translate(str.maketrans(dict.fromkeys(string.punctuation)))
    return res
def remove_hyperlink(word):
    return re.sub(r"http\S+", "", word)
def clean_up(sentence):
    functions = [remove_hyperlink, replace_newline, to_lower, remove_number, remove_punctuation, remove_whitespace, remove_special_characters]
    for o in functions:
        sentence = o(sentence)
    return sentence


x_train = [clean_up(o) for o in emails_train]
x_test = [clean_up(o) for o in emails_test]

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
train_y = le.fit_transform(target_train.values)
test_y = le.transform(target_test.values)

train_y

size = 100 
maximum_feature = 50000
maximum_len = 2000

from tensorflow.keras.preprocessing.text import Tokenizer
tokenizer = Tokenizer(num_words=maximum_feature)

tokenizer.fit_on_texts(x_train)

x_train_features = np.array(tokenizer.texts_to_sequences(x_train) , dtype=object)
x_test_features = np.array(tokenizer.texts_to_sequences(x_test) , dtype=object)

from keras_preprocessing.sequence import pad_sequences
x_train_features = pad_sequences(x_train_features,maxlen=maximum_len)
x_test_features = pad_sequences(x_test_features,maxlen=maximum_len)
x_train_features[0]

from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation
from tensorflow.keras.layers import Bidirectional
from tensorflow.keras.models import Model

import tensorflow as tf
embedding_vecor_length = 32

model = tf.keras.Sequential()
model.add(Embedding(maximum_feature, embedding_vecor_length, input_length=maximum_len))
model.add(Bidirectional(tf.keras.layers.LSTM(64)))
model.add(Dense(16, activation='relu'))
model.add(Dropout(0.1))
model.add(Dense(1, activation='sigmoid'))
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
print(model.summary())

history = model.fit(x_train_features, train_y, batch_size=32, epochs=20, validation_data=(x_test_features, test_y))

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.grid()
plt.show()

y_predict  = [1 if o>0.5 else 0 for o in model.predict(x_test_features)]

cf_matrix =confusion_matrix(test_y,y_predict)

tn, fp, fn, tp = confusion_matrix(test_y,y_predict).ravel()

import seaborn as sns

ax= plt.subplot()
sns.heatmap(cf_matrix, annot=True, ax = ax,cmap='Blues',fmt=''); #annot=True to annotate cells

# labels, title and ticks
ax.set_xlabel('Predicted labels');
ax.set_ylabel('True labels'); 
ax.set_title('Confusion Matrix'); 
ax.xaxis.set_ticklabels(['Not Spam', 'Spam']); ax.yaxis.set_ticklabels(['Not Spam', 'Spam']);

print("Precision: {:.2f}%".format(100 * precision_score(test_y, y_predict)))
print("Recall: {:.2f}%".format(100 * recall_score(test_y, y_predict)))
print("F1 Score: {:.2f}%".format(100 * f1_score(test_y,y_predict)))

f1_score(test_y,y_predict)
